{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ml_utilities as mlutils\n",
    "from loaders import DataLoader\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is the maximum number of unique records that can be obtained with the non-categorical attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 120 feature combinations\n",
      "Maximum number of distinct features and the corresponding feature set:  [(36, [3, 4, 5, 6, 7, 8]), (36, [3, 4, 5, 6, 7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "# Generate all possible combinations of 1 < d <=7 features\n",
    "path = 'C:/Users/alexc/OneDrive/Documents/GitHub/Thesis/Data/solar/flare.data.2.txt'\n",
    "features = range(3,10)\n",
    "feature_combinations = []\n",
    "for m in range(2,len(features)+1):\n",
    "    feature_combinations.append(mlutils.findsubsets(features,m))\n",
    "    \n",
    "# How many feature combinations are there?\n",
    "num_combinations = sum([len(x) for x in feature_combinations])\n",
    "print (\"There are\"+\" \"+str(num_combinations)+\" \"+\"feature combinations\")\n",
    "\n",
    "# Load each of the data sets and calculate the number of unique records\n",
    "unique_records_comb = []\n",
    "max_unique_records = 0\n",
    "unique_records_comb_max = []\n",
    "for combination in itertools.chain(*feature_combinations):\n",
    "    # Load data\n",
    "    loader = DataLoader()\n",
    "    loader.load(path,features=combination,targets=[10])\n",
    "    # Calculate the number of unique records\n",
    "    no_records = mlutils.get_unique_records(loader.features,number=True)\n",
    "    if no_records > max_unique_records:\n",
    "        max_unique_records = no_records\n",
    "    unique_records_comb.append(tuple([no_records,combination]))\n",
    "# Print the feature combinations that generate the maximum number of distinct records\n",
    "for entry in unique_records_comb:\n",
    "        if entry[0] == max_unique_records:\n",
    "            unique_records_comb_max.append(entry)\n",
    "print(\"Maximum number of distinct features and the corresponding feature set: \",unique_records_comb_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data corresponding to the feature combination that maximises # of unique records and has minimum dimensionality\n",
    "min_len = 11 # init. min length to an aribtrary number > feat. set dimensionality\n",
    "for entry in unique_records_comb_max:\n",
    "    if len(entry[1]) < min_len:\n",
    "        min_len = len(entry[1])\n",
    "for entry in unique_records_comb_max:\n",
    "    if len(entry[1]) == min_len:\n",
    "        features = entry[1]\n",
    "        break\n",
    "loader = DataLoader()\n",
    "loader.load(path,features=features,targets=[10])\n",
    "# Extract unique features and targets\n",
    "solar_features = loader.features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
