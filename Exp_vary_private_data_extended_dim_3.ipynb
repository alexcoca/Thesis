{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of performance of net mechanism on a three-dimensional toy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import second_moment_experiments_main as experiment\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex = True)\n",
    "plt.rc('font', family = 'serif')\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "from exputils import extract_data, initialise_netmech_containers, initialise_adassp_reg_containers, \\\n",
    "initialise_netmech_reg_containers, get_expected_statistics, get_optimal_utilities_statistics\n",
    "from baselines import Regression, DPRegression\n",
    "import numpy as np\n",
    "# %matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "exp_name = 'exp_vary_private_data_extended_dim_3'\n",
    "with open ('D:/Thesis/Experiments/exp_vary_private_data_extended_dim_3/' + exp_name, \"rb\") as container:\n",
    "    results = pickle.load(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the performance of the netmechanism for sparse lattices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Setup}$: Draw $25$ samples with the net mechanism set up with $k_f = k_t \\in \\{3,...,6\\}$ for $100$ different data sets.  Compare the expected average RMSE across the $100$ datasets with the results obtained originally for the seed = 23 case. Then compute the expected average RMSE across the $100$ datasets for the ADASSP algorithm and compare the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters list\n",
    "dimensionality = 2\n",
    "num_records = 300\n",
    "test_frac = 0.8\n",
    "batch_size = 500\n",
    "directory = '/home/alexcoca/Thesis/Experiments/exp_vary_private_data_extended_dim_3/'\n",
    "parallel = False\n",
    "save_data = False\n",
    "partition_method = 'fast_2'\n",
    "workers = -1\n",
    "num_samples = 25\n",
    "sample_parallel = False \n",
    "load_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment specific\n",
    "num_points_min = 3\n",
    "min_seed = 0\n",
    "num_points_max = 6\n",
    "num_points_features_vec = range(num_points_min, num_points_max + 1)\n",
    "num_points_targets_vec = range(num_points_min, num_points_max + 1)\n",
    "num_datasets = 100\n",
    "epsilon_vec = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise results data containers\n",
    "results = {key_outer: {key_inner : [] for key_inner in epsilon_vec}  for key_outer in range(num_datasets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results\n",
    "for dataset in range(min_seed, num_datasets):\n",
    "    print (\"Dataset number\", dataset)\n",
    "    for epsilon in epsilon_vec:\n",
    "        for num_points_features, num_points_targets in zip(num_points_features_vec, num_points_targets_vec):\n",
    "            # Only larger cases selected to run in parallel\n",
    "            if num_points_features == 6 and num_points_targets == 6:\n",
    "                parallel = True \n",
    "                workers = 5\n",
    "            else:\n",
    "                parallel = False\n",
    "            results[dataset][epsilon].append(experiment.second_order_moment_experiment(dimensionality = dimensionality, num_records = num_records, \\\n",
    "                                                                                       test_frac = test_frac, batch_size = batch_size,directory = directory, \\\n",
    "                                                                                       parallel = parallel, save_data = save_data,\\\n",
    "                                                                                       partition_method = partition_method, workers = workers, \\\n",
    "                                                                                       num_samples = num_samples, sample_parallel = sample_parallel,\\\n",
    "                                                                                       load_data = load_data, num_points_targets = num_points_targets,\\\n",
    "                                                                                       num_points_features = num_points_features, epsilon = epsilon, \\\n",
    "                                                                                       seed = dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results for latter access\n",
    "exp_name = 'exp_vary_private_data_extended_dim_3'\n",
    "with open (directory + exp_name, \"wb\") as container:\n",
    "    pickle.dump(results, container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental data containers\n",
    "max_utilities, avg_samples_utility, synthetic_datasets_vec, test_set, private_data = \\\n",
    "    initialise_netmech_containers(epsilon_vec, multiple_datasets = True, max_dataset = num_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the results data structure \n",
    "for dataset_number in results.keys():\n",
    "    # Quantities that are epsilon independent \n",
    "    fixed_eps = 0.1\n",
    "    max_utilities[dataset_number], test_set[dataset_number], private_data[dataset_number] = extract_data(results[dataset_number][fixed_eps],\\\n",
    "                                                                                                    multiple_datasets = True, \\\n",
    "                                                                                                    max_dataset = num_datasets, \\\n",
    "                                                                                                    eps_dependent = False)\n",
    "    # Quantities that are epsilon independent\n",
    "    for epsilon in results[dataset_number].keys():\n",
    "        avg_samples_utility[dataset_number][epsilon], synthetic_datasets_vec[dataset_number][epsilon] = \\\n",
    "           extract_data(results[dataset_number][epsilon], multiple_datasets = True, max_dataset = num_datasets, \\\n",
    "                          eps_dependent = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise containers for the regression on the synthetic data sets released with netmechanism\n",
    "net_mech_reg_coefs, predictive_errs_netmech, min_predictive_errs_netmech, mean_predictive_errs_netmech,\\\n",
    "double_std_predictive_errs_netmech = initialise_netmech_reg_containers(epsilon_vec, multiple_datasets = True,\\\n",
    "                                                                        max_dataset = num_datasets)\n",
    "\n",
    "# Initialise containers for the regression on the synthetic data sets with parameters released by ADASSP\n",
    "adassp_reg_coef, predictive_err_adassp, min_predictive_err_adassp, mean_predictive_err_adassp, double_std_predictive_err_adassp\\\n",
    "                                   = initialise_adassp_reg_containers(epsilon_vec, multiple_datasets = True, max_dataset = num_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ADASSP to the private dataset and calculate the predictive error\n",
    "for dataset_number in results.keys():\n",
    "    for epsilon in results[dataset_number].keys():\n",
    "        adassp_regressor = DPRegression()\n",
    "        adassp_reg_coef[dataset_number][epsilon] = adassp_regressor.get_parameters(private_data[dataset_number].features, \\\n",
    "                                                                                   private_data[dataset_number].targets,\\\n",
    "                                                                                   num_samples, epsilon, seed = dataset_number)\n",
    "        predictive_err_adassp[dataset_number][epsilon] = Regression().calculate_predictive_error(private_data[dataset_number].test_data, \\\n",
    "                                                                                                 adassp_reg_coef[dataset_number][epsilon])\n",
    "        min_predictive_err_adassp[dataset_number][epsilon] = np.min(predictive_err_adassp[dataset_number][epsilon])\n",
    "        mean_predictive_err_adassp[dataset_number][epsilon] = np.mean(predictive_err_adassp[dataset_number][epsilon])\n",
    "        double_std_predictive_err_adassp[dataset_number][epsilon] = 2*np.std(predictive_err_adassp[dataset_number][epsilon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression on the datasets released with the net mechanism and calculate predictive error statistics\n",
    "for dataset_number in results.keys():\n",
    "    for epsilon in results[dataset_number].keys():\n",
    "        for synthetic_datasets in synthetic_datasets_vec[dataset_number][epsilon]:\n",
    "            netmech_regressor = Regression()\n",
    "            net_mech_reg_coef = netmech_regressor.fit_data(synthetic_datasets)\n",
    "            net_mech_reg_coefs[dataset_number][epsilon].append(net_mech_reg_coef)\n",
    "            predictive_err_netmech = netmech_regressor.calculate_predictive_error(private_data[dataset_number].test_data, \\\n",
    "                                                                                  net_mech_reg_coef)\n",
    "            predictive_errs_netmech[dataset_number][epsilon].append(predictive_err_netmech)\n",
    "            min_predictive_errs_netmech[dataset_number][epsilon].append(np.min(predictive_err_netmech))\n",
    "            mean_predictive_errs_netmech[dataset_number][epsilon].append(np.mean(predictive_err_netmech))\n",
    "            double_std_predictive_errs_netmech[dataset_number][epsilon].append(2*np.std(predictive_err_netmech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the desired satistics           \n",
    "expected_avg_utility, min_avg_utility, max_avg_utility, expected_mean_predictive_errs_netmech, \\\n",
    "expected_double_std_predictive_errs_netmech, expected_mean_predictive_err_adassp, \\\n",
    "expected_double_std_predictive_err_adassp, expected_min_predictive_errs_netmech, \\\n",
    "min_min_predictive_errs_netmech, max_min_predictive_errs_netmech, expected_min_predictive_err_adassp, \\\n",
    "min_min_predictive_err_adassp, max_min_predictive_err_adassp = get_expected_statistics(avg_samples_utility,\\\n",
    "                                                                    mean_predictive_errs_netmech,\\\n",
    "                                                                    double_std_predictive_errs_netmech,\\\n",
    "                                                                    mean_predictive_err_adassp,\\\n",
    "                                                                    double_std_predictive_err_adassp, \\\n",
    "                                                                    min_predictive_errs_netmech, \\\n",
    "                                                                    min_predictive_err_adassp, \\\n",
    "                                                                    epsilon_vec)\n",
    "expected_optimal_utilities, min_optimal_utilities, max_optimal_utilities = get_optimal_utilities_statistics(max_utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcoordinate = num_points_features_vec\n",
    "# Define the range of epsilon for which various quntities are plotted\n",
    "epsilon_range = [0.1, 0.6, 5.0]\n",
    "epsilon_range = epsilon_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected average samples utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_expected_avg_utility(xcoordinate, expected_avg_samples_utility, expected_optimal_utilities, epsilon):\n",
    "    plt.plot(xcoordinate, expected_avg_samples_utility, 'g--^', label = r'$E[\\mu_u]$' )\n",
    "    plt.plot(xcoordinate, expected_optimal_utilities, 'r*', label = r'$E[opt(u)]$')\n",
    "    plt.xticks(xcoordinate)\n",
    "    plt.xlabel('Lattice denisity (points)', fontsize = 20)\n",
    "    plt.ylabel(r'$\\mu_u$ ($\\varepsilon =' + str(epsilon) + '$)', fontsize = 20)\n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.grid(True)\n",
    "\n",
    "for epsilon in epsilon_range:\n",
    "    plot_expected_avg_utility(xcoordinate, expected_avg_utility[epsilon],\\\n",
    "                            expected_optimal_utilities, epsilon)\n",
    "    plt.plot(xcoordinate, avg_samples_utility[23][epsilon], 'yH', label = r'$\\mu_u^{23}$')\n",
    "    plt.plot(xcoordinate, max_utilities[23], 'cD', label = r'$opt(u)^{23}$')\n",
    "    plt.legend(fontsize = 15, loc = 4)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation of average RMSE with $\\varepsilon$ for various lattice densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variation of RMSE as a function of epsilon\n",
    "expected_rmse_eps_avg_netmech = {key: [] for key in xcoordinate}\n",
    "expected_rmse_eps_std_netmech = {key: [] for key in xcoordinate}\n",
    "expected_rmse_eps_avg_adassp = []\n",
    "expected_prmse_eps_std_adassp = []\n",
    "\n",
    "# Extract data\n",
    "for epsilon in epsilon_vec[0: len(epsilon_vec)]:\n",
    "    # print (\"DEBUG:\", mean_predictive_errs_netmech[epsilon])\n",
    "    # print (\"DEBUG:\", len(mean_predictive_errs_netmech[epsilon]))\n",
    "    for index in xcoordinate:\n",
    "        expected_rmse_eps_avg_netmech[index].append(expected_mean_predictive_errs_netmech[epsilon][index - xcoordinate[0]])\n",
    "        expected_rmse_eps_std_netmech[index].append(expected_double_std_predictive_errs_netmech[epsilon][index - xcoordinate[0]])\n",
    "\n",
    "expected_rmse_eps_avg_adassp = [expected_mean_predictive_err_adassp[epsilon] for epsilon in epsilon_vec[0: len(epsilon_vec)]] \n",
    "expected_rmse_eps_std_adassp = [expected_double_std_predictive_err_adassp[epsilon] for epsilon in epsilon_vec[0: len(epsilon_vec)]]\n",
    "\n",
    "def plot_expected_rmse_avg_epsilon(epsilon_vec, expected_rmse_eps_avg_netmech, expected_rmse_eps_avg_adassp, lattice_density,\\\n",
    "                                   adassp = True):\n",
    "    plt.semilogx(epsilon_vec, expected_rmse_eps_avg_netmech, '--*', label = 'Net mechansim')\n",
    "    if adassp:\n",
    "        plt.plot(epsilon_vec, expected_rmse_eps_avg_adassp, '--*', label = 'ADASSP')\n",
    "        # plt.ylim([0, 1.5]) \n",
    "    plt.xlabel(r'$\\varepsilon$', fontsize = 18)\n",
    "    # plt.yticks(np.arange(0,1.5, step = 0.1))\n",
    "   #  plt.xticks(epsilon_vec)\n",
    "    plt.ylabel('$E[\\mu_{RMSE}]$ (density = ' + str(lattice_density) +  ' points)', fontsize = 18)\n",
    "    plt.legend(fontsize = 14)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "        \n",
    "for lattice_density in xcoordinate:\n",
    "    # print (\"DEBUG, rmse_eps_avg_netmech\", rmse_eps_avg_netmech[lattice_density])\n",
    "    plot_expected_rmse_avg_epsilon(epsilon_vec[0: len(epsilon_vec)], expected_rmse_eps_avg_netmech[lattice_density],\\\n",
    "                                   expected_rmse_eps_avg_adassp, lattice_density, adassp = True)\n",
    "    \n",
    "# Plot average RMSE for ADASSP for selected values of the lattice density on the same graph\n",
    "plt.figure(1)\n",
    "xcoordinate_range = [3, 4, 5, 12, 19]\n",
    "#xcoordinate_range = xcoordinate\n",
    "for lattice_density in xcoordinate_range:\n",
    "    plt.semilogx(epsilon_vec[0: len(epsilon_vec)], expected_rmse_eps_avg_netmech[lattice_density], '--*', \\\n",
    "                 label = 'density = ' + str(lattice_density))\n",
    "plt.plot(epsilon_vec[0: len(epsilon_vec)], expected_rmse_eps_avg_adassp,'-*', label = 'ADASSP')\n",
    "plt.xlabel(r'$\\varepsilon$', fontsize = 20)\n",
    "plt.ylabel('$E[\\mu_{RMSE}]$', fontsize = 20)\n",
    "plt.xticks(epsilon_vec[0: len(epsilon_vec)])\n",
    "#plt.yticks(np.arange(0,3, step = 0.25))\n",
    "#plt.ylim([0, 3]) \n",
    "plt.grid(True)\n",
    "plt.legend(fontsize = 14, bbox_to_anchor=(0.5, 0.85), bbox_transform = plt.gcf().transFigure, loc = 'center', ncol = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation of the RMSE standard deviation with $\\varepsilon$ for different lattice densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_expected_rmse_std_epsilon(epsilon_vec, expected_rmse_eps_std_netmech, expected_rmse_eps_std_adassp, lattice_density,\\\n",
    "                                   adassp = True):\n",
    "    plt.semilogx(epsilon_vec, expected_rmse_eps_std_netmech, '--*', label = 'Net mechansim')\n",
    "    if adassp:\n",
    "        plt.plot(epsilon_vec, expected_rmse_eps_std_adassp, '--*', label = 'ADASSP')\n",
    "        # plt.ylim([0, 1]) \n",
    "    plt.xlabel(r'$\\varepsilon$', fontsize = 18)\n",
    "   # plt.yticks(np.arange(0,5, step = 1))\n",
    "   # plt.ylim([0, 5])\n",
    "   #  plt.xticks(epsilon_vec)\n",
    "    plt.ylabel(r'$\\sigma_{RMSE}$ (density = ' + str(lattice_density) +  ' points)', fontsize = 18)\n",
    "    plt.legend(fontsize = 14)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "        \n",
    "for lattice_density in xcoordinate:\n",
    "    # print (\"DEBUG, expected_rmse_eps_std_netmech\", expected_rmse_eps_std_netmech[lattice_density])\n",
    "    plot_expected_rmse_std_epsilon(epsilon_vec[0: len(epsilon_vec)], expected_rmse_eps_std_netmech[lattice_density],\\\n",
    "                          expected_rmse_eps_std_adassp, lattice_density, adassp = True)\n",
    "\n",
    "# Plot average RMSE for ADASSP for selected values of the lattice density on the same graph\n",
    "plt.figure(1)\n",
    "xcoordinate_range = [3, 4, 5,12,19]\n",
    "for lattice_density in xcoordinate_range:\n",
    "    plt.semilogx(epsilon_vec[0: len(epsilon_vec)], expected_rmse_eps_std_netmech[lattice_density], '--*',\\\n",
    "                 label = 'density = ' + str(lattice_density))\n",
    "plt.plot(epsilon_vec[0: len(epsilon_vec)], expected_rmse_eps_std_adassp,'-*', label = 'ADASSP')\n",
    "plt.xlabel(r'$\\varepsilon$', fontsize = 20)\n",
    "plt.ylabel(r'$\\sigma_{RMSE}$', fontsize = 20)\n",
    "plt.xticks(epsilon_vec[0: len(epsilon_vec)])\n",
    "#plt.yticks(np.arange(0, 10, step = 1))\n",
    "#plt.ylim([0, 10]) \n",
    "plt.grid(True)\n",
    "plt.legend(fontsize = 14, bbox_to_anchor=(0.5, 0.85), bbox_transform = plt.gcf().transFigure, loc = 'center', ncol = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expected_optimal_utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent of epsilon, all the experiments return the same utility\n",
    "plt.plot(xcoordinate, expected_optimal_utilities, 'r*')#, label = r'$E[opt(u)]$')\n",
    "#plt.plot(xcoordinate, max_utilities[23], 'cD', label = r'$opt(u)_{23}$')\n",
    "#plt.plot(xcoordinate, min_optimal_utilities, 'Xk', label =r'$\\min(opt(u))$' )\n",
    "#plt.plot(xcoordinate, max_optimal_utilities, 'Xr', label =r'$\\max(opt(u))$' )\n",
    "plt.xticks(xcoordinate)\n",
    "# plt.yticks(np.arange(-0.07, 0.0, step = 0.01))\n",
    "plt.xlabel('Lattice density (points)', fontsize = 18)\n",
    "plt.ylabel(r'$opt(u)$', fontsize = 18)\n",
    "plt.ylim([-0.1,0])\n",
    "plt.grid(True)\n",
    "#plt.legend(fontsize = 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected minimum sample error for ADASSP vs netmechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expected_min_predictive_errs_netmech)\n",
    "print(expected_min_predictive_err_adassp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_expected_min_rmses(xcoordinate, expected_min_predictive_errs_netmech, expected_min_predictive_err_adassp, epsilon):\n",
    "    plt.plot(xcoordinate, expected_min_predictive_errs_netmech, 'bv', label = 'Net mechanism',  )\n",
    "    plt.plot(xcoordinate, [expected_min_predictive_err_adassp]*len(xcoordinate), 'k^', label = 'ADASSP')\n",
    "    plt.xlabel('Lattice density (points)', fontsize = 18)\n",
    "    plt.ylabel(r'$E[\\min$ RMSE] ($\\varepsilon =' + str(epsilon) + '$)', fontsize = 18)\n",
    "    plt.xticks(xcoordinate)\n",
    "    plt.legend(fontsize = 14)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "for epsilon in epsilon_vec:\n",
    "    plot_expected_min_rmses(xcoordinate, expected_min_predictive_errs_netmech[epsilon], expected_min_predictive_err_adassp[epsilon], \\\n",
    "                   epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum of min sample error for ADASSP vs netmechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data for cross-experiment comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['delta_opt_avg'] = delta_opt_avg\n",
    "data['delta_opt_best'] = delta_opt_best\n",
    "data['max_utilities'] = max_utilities\n",
    "data['rmse_eps_avg_netmech'] = rmse_eps_avg_netmech\n",
    "data['rmse_eps_avg_adassp'] = rmse_eps_avg_adassp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'exp_vary_private_data'\n",
    "with open (directory + filename, 'wb') as container:\n",
    "    pickle.dump(data, container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the raw stats and compare with output of complicated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_out = {key: [] for key in epsilon_vec}\n",
    "means = {key: [] for key in epsilon_vec}\n",
    "mins = {key: [] for key in epsilon_vec}\n",
    "maxs = {key: [] for key in epsilon_vec}\n",
    "for dataset_number in avg_samples_utility.keys():\n",
    "    for epsilon in avg_samples_utility[dataset_number].keys():\n",
    "        helper_out[epsilon].append(avg_samples_utility[dataset_number][epsilon])\n",
    "for epsilon in helper_out.keys():\n",
    "    means[epsilon] = np.mean(helper_out[epsilon], axis = 0)\n",
    "    mins[epsilon] = np.min(helper_out[epsilon], axis = 0)\n",
    "    maxs[epsilon] = np.max(helper_out[epsilon], axis = 0)\n",
    "print (means[0.1])\n",
    "print (expected_avg_utility[0.1])\n",
    "for key in helper_out.keys():\n",
    "    assert np.all(expected_avg_utility[key] == means[key])\n",
    "    assert np.all(min_avg_utility[key] == mins[key])\n",
    "    assert np.all(max_avg_utility[key] == maxs[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test that the data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the results obtained with the parallel code are ordered correctly\n",
    "with open (directory + exp_name, \"rb\") as container:\n",
    "    results = pickle.load(container)\n",
    "    \n",
    "num_points_min =  3 # For correct indexing    \n",
    "    \n",
    "for dataset in range(num_datasets):\n",
    "        for epsilon in epsilon_vec:\n",
    "            for num_points_features, num_points_targets in zip(num_points_features_vec, num_points_targets_vec):\n",
    "                experiment_name = \"s\" + str(dataset) + \"_eps\" + str(epsilon).replace(\".\",\"\") + \"d\" + \\\n",
    "                            str(dimensionality) + \"nt\" + str(num_points_targets) + \\\n",
    "                            \"nf\" + str(num_points_features)\n",
    "                assert experiment_name == results[dataset][epsilon][num_points_features - num_points_min]['experiment_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
